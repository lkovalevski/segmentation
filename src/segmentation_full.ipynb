{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Segmentation example with Credit Risk Data\"\n",
        "author: \"Leandro Kovalevski\"\n",
        "toc: true\n",
        "number-sections: true\n",
        "toc-depth: 2\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    code-summary: \"Show the code\"\n",
        "theme:\n",
        "  light: zephyr\n",
        "  dark: cyborg\n",
        "---"
      ],
      "id": "88524206"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Segmentation example {-}\n",
        "\n",
        "# Settings{-}\n"
      ],
      "id": "27ddf8e1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "dd8ca1c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Setup\n",
        "ROOT = Path.cwd().parent\n",
        "DATA_READY_DIR = ROOT / \"data\" / \"ready\"\n",
        "REPORTS_DIR = ROOT / \"results\" / \"reports\"\n",
        "\n",
        "DATA_FILE = DATA_READY_DIR / \"df_bcra_ready.csv\"\n",
        "df = pd.read_csv(DATA_FILE, sep=';', decimal=',')\n",
        "df = df[df[\"col_3\"] <= 600].copy()\n",
        "df = df.drop(columns=[\"col_18\", \"col_19\"])\n",
        "\n",
        "amt_vars = [\"col_4\", \"col_5\", \"col_11\", \"col_12\", \"col_13\", \"col_14\", \"col_15\", \"col_16\"]\n",
        "for var in amt_vars:\n",
        "    df[f\"{var}_log\"] = np.log1p(df[var])"
      ],
      "id": "699df9ee",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configurations\n",
        "model_dict = {\n",
        "    \"logit\": LogisticRegression(max_iter=1000),\n",
        "    \"rf\": RandomForestClassifier(random_state=42),\n",
        "    \"gb\": GradientBoostingClassifier(random_state=42),\n",
        "    \"nn\": MLPClassifier(max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    \"rf\": {\"n_estimators\": [50, 100, 200], \"max_depth\": [3, 5]},\n",
        "    \"gb\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.1, 0.05]}\n",
        "}"
      ],
      "id": "6f09fcab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run experiment\n",
        "results = []\n",
        "\n",
        "for test_size in [0.05, 0.15, 0.30]:\n",
        "    for model_name, model in model_dict.items():\n",
        "        for n_clusters in range(1, 7):\n",
        "            print(f\"\\n▶ Method: {model_name}, Test: {int(test_size*100)}%, Clusters: {n_clusters}\")\n",
        "\n",
        "            df_run = df.copy()\n",
        "            cluster_ids = None\n",
        "            \n",
        "            if n_clusters > 1:\n",
        "                scaler = StandardScaler()\n",
        "                X_cluster = scaler.fit_transform(df_run[[\"col_3\", \"col_4_log\"]].dropna())\n",
        "                linkage_matrix = linkage(X_cluster, method=\"ward\")\n",
        "                cluster_ids = fcluster(linkage_matrix, n_clusters, criterion=\"maxclust\")\n",
        "                df_run.loc[df_run[[\"col_3\", \"col_4_log\"]].dropna().index, \"cluster\"] = cluster_ids\n",
        "            else:\n",
        "                df_run[\"cluster\"] = 1\n",
        "\n",
        "            X = df_run.drop(columns=[\"id\", \"response\"])\n",
        "            y = df_run[\"response\"]\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "            df_train = X_train.copy()\n",
        "            df_train[\"response\"] = y_train\n",
        "            df_train[\"cluster\"] = df_run.loc[df_train.index, \"cluster\"]\n",
        "            \n",
        "            df_test = X_test.copy()\n",
        "            df_test[\"response\"] = y_test\n",
        "            df_test[\"cluster\"] = df_run.loc[df_test.index, \"cluster\"]\n",
        "\n",
        "            full_y_test, full_pred = [], []\n",
        "            segment_aucs = []\n",
        "\n",
        "            for cid in sorted(df_run[\"cluster\"].dropna().unique()):\n",
        "                train_seg = df_train[df_train[\"cluster\"] == cid]\n",
        "                test_seg = df_test[df_test[\"cluster\"] == cid]\n",
        "\n",
        "                features = train_seg.drop(columns=[\"response\", \"cluster\"]).columns\n",
        "                X_train_s, y_train_s = train_seg[features], train_seg[\"response\"]\n",
        "                X_test_s, y_test_s = test_seg[features], test_seg[\"response\"]\n",
        "\n",
        "                pipe = make_pipeline(SimpleImputer())\n",
        "\n",
        "                if model_name == \"logit\":\n",
        "                    lasso = LogisticRegressionCV(cv=5, penalty='l1', solver='saga', max_iter=1000)\n",
        "                    selector = SelectFromModel(lasso, prefit=False, max_features=20)\n",
        "                    pipe.steps.append((\"selector\", selector))\n",
        "\n",
        "                if model_name in param_grids:\n",
        "                    grid = GridSearchCV(model, param_grids[model_name], cv=3)\n",
        "                    pipe.steps.append((\"model\", grid))\n",
        "                else:\n",
        "                    pipe.steps.append((\"model\", model))\n",
        "\n",
        "                pipe.fit(X_train_s, y_train_s)\n",
        "                y_pred = pipe.predict_proba(X_test_s)[:, 1]\n",
        "                full_y_test.extend(y_test_s)\n",
        "                full_pred.extend(y_pred)\n",
        "                auc = roc_auc_score(y_test_s, y_pred)\n",
        "                segment_aucs.append((cid, auc))\n",
        "\n",
        "            weighted_auc = roc_auc_score(full_y_test, full_pred)\n",
        "            results.append({\n",
        "                \"method\": model_name,\n",
        "                \"test_size\": test_size,\n",
        "                \"n_clusters\": n_clusters,\n",
        "                \"weighted_auc\": weighted_auc,\n",
        "                \"segments\": segment_aucs\n",
        "            })"
      ],
      "id": "47aae4b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Save results\n",
        "final = pd.DataFrame(results)\n",
        "filename = f\"results_{len(model_dict)}methods_{3}samples_6clusters.csv\"\n",
        "final.to_csv(REPORTS_DIR / filename, index=False)"
      ],
      "id": "b1b126ab",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Re-import required libraries after kernel reset\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "df_results = final.copy()\n",
        "\n",
        "# Clean formatting for better visualization\n",
        "df_results[\"method\"] = df_results[\"method\"].str.upper()\n",
        "df_results[\"segmented\"] = df_results[\"segmented\"].map({0: \"No\", 1: \"Yes\"})\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "sns.stripplot(\n",
        "    data=df_results,\n",
        "    x=\"method\",\n",
        "    y=\"auc_weighted\",\n",
        "    hue=\"segmented\",\n",
        "    dodge=True,\n",
        "    jitter=True,\n",
        "    alpha=0.7,\n",
        "    palette=\"Set1\"\n",
        ")\n",
        "\n",
        "plt.title(\"Comparación de AUC por Método y Segmentación\")\n",
        "plt.ylabel(\"AUC ponderado\")\n",
        "plt.xlabel(\"Método de Modelado\")\n",
        "plt.legend(title=\"¿Segmentado?\")\n",
        "plt.ylim(0.5, 1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "b4ad53d0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}